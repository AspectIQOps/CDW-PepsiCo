services:
  etl-analytics:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: pepsico-etl-analytics
    environment:
      # Database connection (from SSM)
      - DB_HOST=${DB_HOST}
      - DB_NAME=cost_analytics_db
      - DB_USER=etl_analytics
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_PORT=5432
      
      # AWS Configuration
      - AWS_REGION=us-east-2
      - AWS_DEFAULT_REGION=us-east-2
      
      # SSM Parameter paths for credentials
      - SSM_APPDYNAMICS_PREFIX=/pepsico/appdynamics
      - SSM_SERVICENOW_PREFIX=/pepsico/servicenow
      
      # Pipeline configuration
      - PIPELINE_MODE=full
      - LOG_LEVEL=INFO
      
    volumes:
      - ./scripts/etl:/app/scripts/etl
      - ./sql:/app/sql
      - ./logs:/app/logs
    
    command: >
      bash -c "
        echo 'Starting Analytics ETL Pipeline...' &&
        echo 'Database: cost_analytics_db' &&
        echo 'User: etl_analytics' &&
        echo '' &&
        python3 /app/scripts/etl/run_pipeline.py
      "
    
    restart: "no"
    
    networks:
      - analytics-network

networks:
  analytics-network:
    driver: bridge